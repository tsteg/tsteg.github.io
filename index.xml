<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Anecdotal Evidence on Anecdotal Evidence</title>
    <link>/</link>
    <description>Recent content in Anecdotal Evidence on Anecdotal Evidence</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Tim Steggall.</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>#TidyTuesday Week 37: NYC Restaurant Inspections</title>
      <link>/post/tidytuesday-nycrestaurants/</link>
      <pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday-nycrestaurants/</guid>
      <description>&lt;p&gt;Week 2! Again, I found the most difficult part of this process to be diving into a random set of data and trying to pull out something interesting. Toss me some baseball or political data, and I have an idea of the questions I want to ask, but data on NYC restaurant inspections is a little trickier.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-12-11&#34;&gt;NYC Restaurant Inspections data&lt;/a&gt; each row is a unique inspection/violation - so one restaurant may have multiple records from the same date, but with different violations. Meaning the number of restaurants per borough, by cuisine, etc. are skewed towards the restaurants that received multiple violations.&lt;/p&gt;
&lt;p&gt;So the first thing I had to do was decide - did I want to look at restaurant level data, something like cuisine by borough? Or do an analysis of the inspections?&lt;/p&gt;
&lt;p&gt;Of course, I ended up making 2 charts - &lt;strong&gt;The # of Inspections per Borough per Year&lt;/strong&gt;, and &lt;strong&gt;Cuisines with the Highest Percentage of Critical Violations.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;datasetup&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data/Setup&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(skimr)
library(janitor)

restaurants_raw &amp;lt;- read_csv(&amp;quot;https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv&amp;quot;)

## use janitor::clean_names to put column names in snake_case
## mutate boro to replace all &amp;quot;Missing&amp;quot; values with zipcode == 11249 to &amp;quot;BROOKLYN&amp;quot;&amp;quot; - leaves only 4 NA values

restaurants &amp;lt;- restaurants_raw %&amp;gt;%
  clean_names() %&amp;gt;%
  select (-phone, -grade_date, -record_date, -building, - street) %&amp;gt;%
  mutate(boro = if_else(boro == &amp;quot;Missing&amp;quot;, case_when(boro == &amp;quot;Missing&amp;quot; &amp;amp; zipcode == 11249 ~ &amp;quot;BROOKLYN&amp;quot;), boro),
         inspection_date = mdy(inspection_date)) %&amp;gt;%
  filter(!is.na(boro))

restaurants$cuisine_description[str_detect(restaurants$cuisine_description, &amp;quot;Latin&amp;quot;)] &amp;lt;- &amp;quot;Latin&amp;quot; 

theme_set(theme_light())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;inspections-per-borough-per-year&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Inspections per borough per year&lt;/h3&gt;
&lt;p&gt;There’s only data for the past couple of years (since 2011), but I started by looking at the number of inspections per borough per year. As mentioned above, each row in the data set corresponds to a violation uncovered during an inspection - so a single inspection of one restaurant might have multiple rows documenting multiple violations. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;restaurants %&amp;gt;% 
  filter(dba == &amp;quot;12 CHAIRS&amp;quot;) %&amp;gt;%
  select(camis, dba, inspection_date, violation_code) %&amp;gt;%
  arrange(inspection_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 35 x 4
##       camis dba       inspection_date violation_code
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;date&amp;gt;          &amp;lt;chr&amp;gt;         
##  1 41006043 12 CHAIRS 2015-12-17      02B           
##  2 41006043 12 CHAIRS 2015-12-17      10F           
##  3 41006043 12 CHAIRS 2015-12-17      05D           
##  4 41006043 12 CHAIRS 2015-12-17      02G           
##  5 41006043 12 CHAIRS 2015-12-17      10B           
##  6 41006043 12 CHAIRS 2015-12-17      04J           
##  7 41006043 12 CHAIRS 2015-12-17      06C           
##  8 41006043 12 CHAIRS 2016-01-12      10F           
##  9 41006043 12 CHAIRS 2016-01-12      06C           
## 10 41006043 12 CHAIRS 2016-06-21      02H           
## # ... with 25 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I needed the actual number of inspections, and not the number of &lt;strong&gt;violations&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspections &amp;lt;- restaurants %&amp;gt;%
  select(camis, dba, boro, inspection_date) %&amp;gt;%
  distinct(camis, dba, boro, inspection_date)

inspections_by_year &amp;lt;- inspections %&amp;gt;%
  mutate(year = year(inspection_date)) %&amp;gt;%
  group_by(year, boro) %&amp;gt;%
  summarize(inspections = n()) %&amp;gt;%
  filter(year &amp;gt; 2014)

inspections_by_year %&amp;gt;%
  ggplot(aes(x = year, y = inspections, color = boro)) +
  geom_line(size = 0.7) +
  labs(x = &amp;quot;Year&amp;quot;, y = &amp;quot;# of Inspections&amp;quot;, title = &amp;quot;# of Inspections per Borough per Year&amp;quot;,
       color = &amp;quot;Borough&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-17-tidytuesday-nycrestaurants_files/figure-html/inspections-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cuisines-with-the-highest-percentage-of-critical-violations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cuisines with the Highest Percentage of Critical Violations&lt;/h3&gt;
&lt;p&gt;Second I wanted to answer the question - If I’m travelling to NYC, what types of cuisines should I avoid? So I looked for the cuisines with the highest percentage of critical violations. (Warning - this got a bit messier than anticipated, so I’m apologizing in advance for some unruly code)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;critical_inspections &amp;lt;- restaurants %&amp;gt;%
  select(camis, dba, boro, cuisine_description, critical_flag) %&amp;gt;%
  mutate(critical = ifelse(critical_flag == &amp;quot;Critical&amp;quot;, 1, 0)) 

critical_by_cuisine &amp;lt;- critical_inspections %&amp;gt;%
  group_by(cuisine_description) %&amp;gt;%
  summarize(violations = n(),
            critical = sum(critical),
            non_critical = violations - critical,
            percent_critical = round(critical/violations, 3)) %&amp;gt;%
  filter(violations &amp;gt;= 5000) %&amp;gt;%
  arrange(desc(percent_critical))

top_critical_cuisine &amp;lt;- critical_by_cuisine %&amp;gt;%
  head(n = 15) 

top_critical_cuisine&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 5
##    cuisine_description violations critical non_critical percent_critical
##    &amp;lt;chr&amp;gt;                    &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
##  1 Indian                    6466    3781.        2685.            0.585
##  2 Chinese                  40080   23292.       16788.            0.581
##  3 Korean                    5243    3041.        2202.            0.580
##  4 Pizza/Italian             8295    4810.        3485.            0.580
##  5 Delicatessen              6012    3478.        2534.            0.579
##  6 Asian                     6306    3645.        2661.            0.578
##  7 Spanish                  11595    6692.        4903.            0.577
##  8 Thai                      5103    2941.        2162.            0.576
##  9 Japanese                 13682    7861.        5821.            0.575
## 10 Latin                    17082    9762.        7320.            0.571
## 11 Bakery                   11812    6654.        5158.            0.563
## 12 Italian                  15914    8880.        7034.            0.558
## 13 Mexican                  15536    8612.        6924.            0.554
## 14 Jewish/Kosher             5546    3055.        2491.            0.551
## 15 Pizza                    17512    9582.        7930.            0.547&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To generate the plot I wanted, I had to gather the data, as shown below. The last two steps - creating &lt;code&gt;cuisine_gather_totals&lt;/code&gt; and left joining with &lt;code&gt;cuisine_gather&lt;/code&gt;, was completed after I had made the initial plot. I realized I needed the percentage of critical violations in a different format than &lt;code&gt;cuisine_gather&lt;/code&gt; provided.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cuisine_gather &amp;lt;- top_critical_cuisine %&amp;gt;%
  select(cuisine_description, critical, non_critical) %&amp;gt;%
  gather(key = violations, value = value, critical:non_critical) %&amp;gt;%
  arrange(cuisine_description)

cuisine_gather_totals &amp;lt;- cuisine_gather %&amp;gt;%  
  group_by(cuisine_description) %&amp;gt;%
  summarize(total = sum(value))

cuisine_gather_join &amp;lt;- cuisine_gather %&amp;gt;%
  left_join(cuisine_gather_totals, by = c(&amp;quot;cuisine_description&amp;quot; = &amp;quot;cuisine_description&amp;quot;)) %&amp;gt;%
  mutate(perc = round(value/total,3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cuisine_gather_join &amp;lt;- cuisine_gather_join %&amp;gt;%
  mutate(labelpos = ifelse(violations == &amp;quot;critical&amp;quot;, value/2, (total - value/2)))

cuisine_gather_join %&amp;gt;%
  ggplot(aes(x = fct_reorder2(cuisine_description, violations, perc), y = value, fill = fct_rev(violations))) +
    geom_bar(stat = &amp;quot;identity&amp;quot;) +
  coord_flip() +
  scale_fill_manual(values = c(&amp;quot;gray76&amp;quot;, &amp;quot;indianred2&amp;quot;)) +
  labs(x = &amp;quot;Cuisine&amp;quot;, y = &amp;quot;# of Inspections&amp;quot;, 
       title = &amp;quot;Cuisines with the Highest Percentage of Critical Violations&amp;quot;) +
  guides(fill = guide_legend(title = &amp;quot;Violation Type&amp;quot;)) +
  geom_text(aes(label = paste0(100*perc, &amp;quot;%&amp;quot;), y = labelpos), size = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-17-tidytuesday-nycrestaurants_files/figure-html/plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While informative, I’m not avoiding Chinese, Italian, Delis, Bakeries, or Japanese while in New York…&lt;/p&gt;
&lt;p&gt;Also, not exactly the best designed visualization. The “# of Inspections” x-axis kind of makes it difficult to understand, and the varied number of inspections makes the sorting fct_reorder kind of a pain. Probably not how I would do it again, but overall good practice.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;resources&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Resources&lt;/h3&gt;
&lt;p&gt;I wanted to highlight and link to a couple of the resources I used while working on this. These helped generate some ideas and get through a couple of the trickier spots.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=em4FXPf4H-Y&amp;amp;t=1330s&#34;&gt;David Robinson’s Tidy Tuesday screencast&lt;/a&gt; - these are a weekly must watch. Watching a professional data scientist at work is an unbelievable resource, and the amount of knowledge in each of these videos is amazing.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/26079137/ggplot-use-numeric-values-to-fill-stacked-bar-charts&#34;&gt;Stack Overflow - “ggplot - use numeric values to fill stacked bar charts”&lt;/a&gt;: Needed this to figure out how to divide the columns in the bar chart up proportionally by critical/non-critical violations.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/44724580/in-rs-ggplot2-how-to-add-percentage-labels-to-a-stacked-barplot-with-percenta&#34;&gt;Stack Overflow - “In R’s ggplot2, how to add percentage labels to a stacked barplot, with percentage values taken from separate columns?”&lt;/a&gt;: Needed this to label the columns with the percentages.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gitlab.com/tidy_tuesday/Week_37&#34;&gt;Dave Bloom’s TidyTuesday plot&lt;/a&gt;: I just really liked this random guy’s theme, then I also borrowed from his code to recode “Latin” in the cuisine_description.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Color of Law by Richard Rothstein</title>
      <link>/post/color-of-law/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/color-of-law/</guid>
      <description>&lt;p&gt;&lt;em&gt;The Color of Law&lt;/em&gt; starts by presenting a series of Supreme Court decisions that cemented and popularized the myth of &lt;em&gt;de facto&lt;/em&gt; segregation, not just in American jurisprudence, but in our culture. Rothstein points to opinions from Justice Potter Stewart in 1974, Justice Anthony Kennedy in 1992, and finishes with this quote from a Chief Justice John Roberts in 2007: “Where [racial imbalance] is a product not of state action but of private choices, it does not have constitutional implications.” Rothstein spends the next 200+ pages methodically and systematically dismantling the argument that segregation was simply a product of social choices, and not the result of policies enacted by the federal, state and local governments (&lt;em&gt;de jure segregation&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;This book is clearly the work of years of research, and the evidence is damning. At times the book is a bit dry and dense, but the magnitude of evidence is necessary and overwhelming. Rothstein goes point by point - examining housing contracts, zoning laws, public housing mandates, state sanctioned violence, suppressed incomes, and more to refute the myth of de facto segregation that has taken hold in American society. Furthermore, Rothstein provides personal stories of the impact of the different forms of discrimination - if the research, facts, and explanation of the laws weren’t enough, these stories provoke an emotional reaction. Similar to &lt;em&gt;The New Jim Crow&lt;/em&gt;, &lt;em&gt;The Color of Law&lt;/em&gt; shines a bright light on government-approved injustice, and makes the argument that unless we actively work to change, this default &lt;em&gt;de facto&lt;/em&gt; explanation will allow our government and communities to look the other way while people continue to suffer.&lt;/p&gt;
&lt;div id=&#34;related-readings&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Related Readings&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;http://www.tampabay.com/projects/2015/investigations/pinellas-failure-factories/&#34;&gt;Failure Factories in Florida&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“On Dec. 18, 2007, the Pinellas County School Board abandoned integration. They justified the vote with bold promises: Schools in poor, black neighborhoods would get more money, more staff, more resources. They delivered none of that. This is the story of how district leaders turned five once-average schools into Failure Factories.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;An amazing example of local journalism - a multi-part, Pulitzer Prize winning series by the Tampa Bay Times that examines the public schools in South St. Petersburg.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.scientificamerican.com/article/pollution-poverty-people-color-asthma-inner-city/&#34;&gt;Pollution, Poverty, and People of Color&lt;/a&gt;: Another multi-part series detailing the relationship between poverty and asthma in low income communities across the country. &lt;a href=&#34;https://www.scientificamerican.com/article/pollution-poverty-people-color-living-industry/&#34;&gt;Part 2&lt;/a&gt; focuses on Richmond, CA and discusses many of the same issues related to housing, zoning, and segregation as Rothstein. It’s devestating that our society simply accepts this as the current default, even in places like the progressive Bay Area.&lt;/p&gt;
&lt;p&gt;Continuing with the CA theme - Rothstein mentions Berkeley, Palo Alto, and Marin as cities that exploited housing laws to discriminate against African Americans. Three very affluent and liberal cities that “benefitted” from these laws. California is in the midst of a housing crisis, and of course, most of the housing plans are being met with familiar NIMBY arguments. After reading this book, those arguments sure seem a hell of a lot weaker.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Similar books:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Evicted-Poverty-Profit-American-City/dp/0553447459/ref=sr_1_2?ie=UTF8&amp;amp;qid=1544640231&amp;amp;sr=8-2&amp;amp;keywords=evicted+poverty+and+profit+in+the+american+city&#34;&gt;Evicted&lt;/a&gt; by Matthew Desmond&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/New-Jim-Crow-Incarceration-Colorblindness/dp/1595586431/ref=sr_1_1?ie=UTF8&amp;amp;qid=1544640261&amp;amp;sr=8-1&amp;amp;keywords=the+new+jim+crow&#34;&gt;The New Jim Crow&lt;/a&gt; by Michelle Alexander&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Ghettoside-True-Story-Murder-America/dp/0385529996/ref=sr_1_1?ie=UTF8&amp;amp;qid=1544640300&amp;amp;sr=8-1&amp;amp;keywords=ghettoside&#34;&gt;Ghettoside&lt;/a&gt; by Jill Leovy&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;future-blog-posts&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Future Blog Posts&lt;/h4&gt;
&lt;p&gt;I would love to try to map current census data to the old zoning maps to see how much these communities have changed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Demographics&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Income&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Wealth&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Healthcare options and outcomes&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Representation - this might actually be the most interesting. If, as I suspect, the demographics haven’t changed much, who is representing these communities in government?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>#TidyTuesday Week 36: Medium Blog Posts</title>
      <link>/post/tidy-tuesday-medium/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tidy-tuesday-medium/</guid>
      <description>&lt;p&gt;So my first attempt at a #TidyTuesday - it’s not quite as easy as &lt;a href=&#34;https://www.youtube.com/watch?v=C69QyycHsgE&#34;&gt;DRob makes it look!&lt;/a&gt; The data on Medium blog posts was interesting and in good shape, but for my first #TidyTuesday post I had a bit of a brain cramp generating ideas. I’ve been listening to a podcast lately that talks about the importance of a consistent posting schedule for bloggers, so I tried to dig into the relationship between an author’s posting schedule and the number of claps they receive. Unfortunately I didn’t find much; I might dig a little deeper with the full Kaggle dataset in the future and not just the AI related tags.&lt;/p&gt;
&lt;p&gt;After spending a little too much time looking into that relationship, I decided to keep things simple for my first post and threw together some straightforward visualizations looking at the distribution of blog posts across days of the week, the most prolific authors, and the posting routines of the individual prolific authors.&lt;/p&gt;
&lt;div id=&#34;data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)


medium &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-12-04/medium_datasci.csv&amp;quot;)

theme_set(theme_light())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;on-what-days-of-the-week-are-articles-typically-posted&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;On what days of the week are articles typically posted?&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lubridate)

medium %&amp;gt;%
  unite(date, year, month, day, sep = &amp;quot;-&amp;quot;) %&amp;gt;%
  mutate(day = wday(date, label = TRUE)) %&amp;gt;%
  count(day, sort=TRUE) %&amp;gt;%
  ggplot(aes(x=day, y=n, fill = day)) +
  geom_col() +
  labs(title = &amp;quot;Posts per Day of the Week&amp;quot;, y = &amp;quot;# of Posts&amp;quot;) +
  geom_text(aes(label = n, vjust = -0.3)) +
  theme(legend.position = &amp;quot;none&amp;quot;,
        axis.title.x = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-06-tidy-tuesday-medium_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Makes sense that writers wouldn’t post on weekends - readership is probably less consistent on weekends, and wouldn’t want potentially popular posts to get overlooked.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;who-are-the-most-prolific-authors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Who are the most prolific authors?&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;medium %&amp;gt;%
  count(author, sort = TRUE) %&amp;gt;%
  drop_na() %&amp;gt;%
  top_n(n=10) %&amp;gt;%
  ggplot(aes(x=fct_reorder(author,n), y=n)) +
  geom_point() +
  labs(title = &amp;quot;Most prolific authors&amp;quot;, y = &amp;quot;Number of Articles&amp;quot;, x = &amp;quot;Author&amp;quot;) +
  coord_flip()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-06-tidy-tuesday-medium_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-the-posting-schedule-of-the-most-prolific-authors-top-10-authors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What is the posting schedule of the most prolific authors (Top 10 authors)&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prolific &amp;lt;- medium %&amp;gt;%
  count(author, sort = TRUE) %&amp;gt;%
  drop_na() %&amp;gt;%
  top_n(n=10)

author_by_day &amp;lt;- medium %&amp;gt;%
  unite(date,year, month, day, sep=&amp;quot;-&amp;quot;) %&amp;gt;%
  mutate(day = wday(date, label = TRUE)) %&amp;gt;%
  filter(!is.na(author))

author_by_day %&amp;gt;%
  group_by(author,day) %&amp;gt;%
  summarize(posts = n()) %&amp;gt;%
  filter(author %in% prolific$author) %&amp;gt;%
  ggplot(aes(x=factor(day), y=posts, color = author, group = author)) +
  geom_line(size = 1) +
  labs(title = &amp;quot;What is the posting schedule for the top authors?&amp;quot;,
       y = &amp;quot;# of Posts&amp;quot;) +
  theme(axis.title.x = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-06-tidy-tuesday-medium_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I guess if you want to be the most prolific writer, it makes sense that you would have a stable publishing schedule, which Yves Mulkers does. Yves also publishes more often on weekends, in contrast to nearly every other author. Synced and Alibaba Cloud appear to take weekends off, while Corsair’s Publishing doesn’t post on Sundays. Yves is just on a different level from everyone else.&lt;/p&gt;
&lt;p&gt;Relatively straightforward first #TidyTuesday but thanks for making it all the way to the bottom! Let me know if you have any questions or ways to improve.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2017 Reading List</title>
      <link>/post/2017-book-list/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-book-list/</guid>
      <description>&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Strangers in Their Own Land by Arlie Russell Hochschild&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Undoing Project by Michael Lewis&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;What it Takes by Richard Ben Cramer&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Midnight Riot by Ben Aaronovitch&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Just Mercy by Bryan Stevenson&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Moon Over Soho by Ben Aaronovitch&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Data Science for Business by Foster Provost and Tom Fawcett&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Unwinding by George Packer&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Whispers Underground by Ben Aaronovitch&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Hillbilly Elegy by J.D. Vance&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Broken Homes by Ben Aaronovitch&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Foxglove Summer by Ben Aaronovitch&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Hanging Tree by Ben Aaronovitch&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Evicted by Matthew Desmond&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;SQL Queries for Mere Mortals by John L. Viescas and Michael J. Hernandez&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Magic of Thinking Big by David J. Schwartz&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;White Teeth by Zadie Smith&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;When Breath Becomes Air by Paul Kalanithi&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Attention Merchants by Tim Wu&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Hike by Drew Magary&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Information: A History, a Theory, a Flood by James Gleick&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Team of Teams by Gen. Stanley McChrystal&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Innovators by Walter Isaacson&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Master Switch by Tim Wu&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Pattern Recognition by William Gibson&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Before the Storm by Rick Perlstein&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Dark Money by Jane Mayer&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Restaurant at the End of the Universe by Douglas Adams&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Principles by Ray Dalio&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;A Legacy of Spies by John Le Carre&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Spook Country by William Gibson&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;R for Data Science by Hadley Wickham and Garrett Grolemund&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Power Broker: Robert Moses and the Fall of New York by Robert A. Caro&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Zero History by William Gibson&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>2018 Reading List</title>
      <link>/post/reading-list/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/reading-list/</guid>
      <description>&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The Three-Body Problem by Cixin Liu, trans. by Ken Liu&lt;/li&gt;
&lt;li&gt;Shoe Dog: A Memoir by the Creator of Nike by Phil Knight&lt;/li&gt;
&lt;li&gt;Killers of the Flower Moon: The Osage Murders and the Birth of the FBI by David Grann&lt;/li&gt;
&lt;li&gt;Gnomon by Nick Harkaway&lt;/li&gt;
&lt;li&gt;The Ocean at the End of the Lane by Neil Gaiman&lt;/li&gt;
&lt;li&gt;The Catcher in the Rye by J.D. Salinger&lt;/li&gt;
&lt;li&gt;Siddhartha by Herman Hesse&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Ministry of Utmost Happiness by Arundhati Roy&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Broken Angels by Richard K. Morgan&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Political Campaign Desk Reference by Michael McNamara&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;“Surely You’re Joking, Mr. Feynman!” by Richard Feynman&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Fifth Season by N.K. Jemisin&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Obelisk Gate by N.K. Jemisin&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Stone Sky by N.K. Jemisin&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;White Noise by Don DeLillo&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Yes We (Still) Can: Politics In the Age of Obama, Twitter, and Trump by Dan Pfeiffer&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The Secret History by Donna Tartt&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;A Gentleman in Moscow by Amor Towles&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Afterparty by Daryl Gregory&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Death by Meeting by Patrick Lencioni&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Winners Take All: The Elite Charade of Changing the World by Anand Giridharadas&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tsteggall.github.io/post/color-of-law/&#34;&gt;The Color of Law: A Forgotten History of How Our Government Segregated America&lt;/a&gt; by Richard Rothstein&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Stubborn Attachments by Tyler Cowen&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Black Panther: A Nation Under Our Feet Book 1 by Ta-Nehisi Coates&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Open: An Autobiography by Andre Agassi&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Currently Reading:&lt;/strong&gt; The Start-up of You by Reid Hoffman &amp;amp; The Hard Thing About Hard Things by Ben Horowitz&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Coming Soon</title>
      <link>/project/coming-soon/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/coming-soon/</guid>
      <description>&lt;p&gt;I plan to use the &lt;strong&gt;Projects&lt;/strong&gt; space for larger, primarily data driven analyses. These larger projects will likely/hopefully tie into multiple blog posts.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
